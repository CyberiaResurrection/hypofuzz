
@article{MacIver2019,
  doi = {10.21105/joss.01891},
  url = {https://doi.org/10.21105/joss.01891},
  year = {2019},
  publisher = {The Open Journal},
  volume = {4},
  number = {43},
  pages = {1891},
  author = {David MacIver and Zac Hatfield-Dodds and Many Contributors},
  title = {Hypothesis: A new approach to property-based testing},
  journal = {Journal of Open Source Software}
}

% TODO: to be replaced by formal citation as soon as one is available
@Unpublished{MacIver2020,
  author    = {David MacIver and Alastair Donaldson},
  title     = {Test-Case Reduction via Test-Case Generation: Insights From the Hypothesis Reducer},
  publisher = {ECOOP},
  url       = {https://drmaciver.github.io/papers/reduction-via-generation-preview.pdf},
  note      = {to be published in \url{https://2020.ecoop.org/details/ecoop-2020-papers/13/Test-Case-Reduction-via-Test-Case-Generation-Insights-From-the-Hypothesis-Reducer}}
}

@inproceedings{TargetedPBT,
  author = {L\"{o}scher, Andreas and Sagonas, Konstantinos},
  title = {Targeted Property-Based Testing},
  year = {2017},
  isbn = {9781450350761},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://proper-testing.github.io/papers/issta2017.pdf},
  doi = {10.1145/3092703.3092711},
  booktitle = {Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis},
  pages = {46–56},
  numpages = {11},
  keywords = {Search-based testing, PropEr, QuickCheck, Property-based testing},
  location = {Santa Barbara, CA, USA},
  series = {ISSTA 2017}
}

@inproceedings{AutomatingTargetedPBT,
  author={A. {Löscher} and K. {Sagonas}},
  booktitle={2018 IEEE 11th International Conference on Software Testing, Verification and Validation (ICST)},
  title={Automating Targeted Property-Based Testing},
  url = {https://proper-testing.github.io/papers/icst2018.pdf},
  doi = {10.1109/ICST.2018.00017},
  year={2018},
  volume={},
  number={},
  pages={70-80},
}

@incollection{fuzzingbook2019,
    author = {Andreas Zeller and Rahul Gopinath and Marcel B{\"o}hme and Gordon Fraser and Christian Holler},
    booktitle = {The Fuzzing Book},
    title = {The Fuzzing Book},
    year = {2019},
    publisher = {Saarland University},
    howpublished = {\url{https://www.fuzzingbook.org/}},
    note = {Retrieved 2019-09-09 16:42:54+02:00},
    url = {https://www.fuzzingbook.org/},
    urldate = {2019-09-09 16:42:54+02:00}
}

@article{10.1145/2499370.2462173,
author = {Chen, Yang and Groce, Alex and Zhang, Chaoqiang and Wong, Weng-Keen and Fern, Xiaoli and Eide, Eric and Regehr, John},
title = {Taming Compiler Fuzzers},
year = {2013},
issue_date = {June 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/2499370.2462173},
doi = {10.1145/2499370.2462173},
abstract = {Aggressive random testing tools ("fuzzers") are impressively effective at finding compiler bugs. For example, a single test-case generator has resulted in more than 1,700 bugs reported for a single JavaScript engine. However, fuzzers can be frustrating to use: they indiscriminately and repeatedly find bugs that may not be severe enough to fix right away. Currently, users filter out undesirable test cases using ad hoc methods such as disallowing problematic features in tests and grepping test results. This paper formulates and addresses the fuzzer taming problem: given a potentially large number of random test cases that trigger failures, order them such that diverse, interesting test cases are highly ranked. Our evaluation shows our ability to solve the fuzzer taming problem for 3,799 test cases triggering 46 bugs in a C compiler and 2,603 test cases triggering 28 bugs in a JavaScript engine.},
journal = {SIGPLAN Not.},
month = jun,
pages = {197–208},
numpages = {12},
keywords = {fuzz testing, compiler testing, random testing, compiler defect, bug reporting, test-case reduction, automated testing}
}

@inproceedings{TamingCompilerFuzzers,
author = {Chen, Yang and Groce, Alex and Zhang, Chaoqiang and Wong, Weng-Keen and Fern, Xiaoli and Eide, Eric and Regehr, John},
title = {Taming Compiler Fuzzers},
year = {2013},
isbn = {9781450320146},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {http://www.cs.utah.edu/~regehr/papers/pldi13.pdf},
doi = {10.1145/2491956.2462173},
abstract = {Aggressive random testing tools ("fuzzers") are impressively effective at finding compiler bugs. For example, a single test-case generator has resulted in more than 1,700 bugs reported for a single JavaScript engine. However, fuzzers can be frustrating to use: they indiscriminately and repeatedly find bugs that may not be severe enough to fix right away. Currently, users filter out undesirable test cases using ad hoc methods such as disallowing problematic features in tests and grepping test results. This paper formulates and addresses the fuzzer taming problem: given a potentially large number of random test cases that trigger failures, order them such that diverse, interesting test cases are highly ranked. Our evaluation shows our ability to solve the fuzzer taming problem for 3,799 test cases triggering 46 bugs in a C compiler and 2,603 test cases triggering 28 bugs in a JavaScript engine.},
booktitle = {Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {197–208},
numpages = {12},
keywords = {fuzz testing, bug reporting, compiler defect, test-case reduction, random testing, compiler testing, automated testing},
location = {Seattle, Washington, USA},
series = {PLDI '13}
}

@article{QuickCheck,
  author = {Claessen, Koen and Hughes, John},
  title = {QuickCheck: A Lightweight Tool for Random Testing of Haskell Programs},
  year = {2000},
  publisher = {Association for Computing Machinery},
  url = {https://doi.org/10.1145/357766.351266},
  doi = {10.1145/357766.351266},
  journal = {Proceedings of the Fifth ACM SIGPLAN International Conference on Functional Programming},
}

@inproceedings{OneTestToRuleThemAll,
  doi = {10.1145/3092703.3092704},
  url = {https://agroce.github.io/issta17.pdf},
  year = {2017},
  publisher = {{ACM} Press},
  author = {Alex Groce and Josie Holmes and Kevin Kellar},
  title = {One test to rule them all},
  booktitle = {Proceedings of the 26th {ACM} {SIGSOFT} International Symposium on Software Testing and Analysis - {ISSTA} 2017}
}

@inproceedings{SwarmTesting,
author = {Groce, Alex and Zhang, Chaoqiang and Eide, Eric and Chen, Yang and Regehr, John},
title = {Swarm Testing},
year = {2012},
isbn = {9781450314541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://www.cs.utah.edu/~regehr/papers/swarm12.pdf},
doi = {10.1145/2338965.2336763},
abstract = { Swarm testing is a novel and inexpensive way to improve the diversity of test cases generated during random testing. Increased diversity leads to improved coverage and fault detection. In swarm testing, the usual practice of potentially including all features in every test case is abandoned. Rather, a large “swarm” of randomly generated configurations, each of which omits some features, is used, with configurations receiving equal resources. We have identified two mechanisms by which feature omission leads to better exploration of a system’s state space. First, some features actively prevent the system from executing interesting behaviors; e.g., “pop” calls may prevent a stack data structure from executing a bug in its overflow detection logic. Second, even when there is no active suppression of behaviors, test features compete for space in each test, limiting the depth to which logic driven by features can be explored. Experimental results show that swarm testing increases coverage and can improve fault detection dramatically; for example, in a week of testing it found 42% more distinct ways to crash a collection of C compilers than did the heavily hand-tuned default configuration of a random tester. },
booktitle = {Proceedings of the 2012 International Symposium on Software Testing and Analysis},
pages = {78–88},
numpages = {11},
location = {Minneapolis, MN, USA},
series = {ISSTA 2012}
}

@article{Fuzz1990,
    author = {Miller, Barton P. and Fredriksen, Louis and So, Bryan},
    title = {An Empirical Study of the Reliability of UNIX Utilities},
    year = {1990},
    issue_date = {Dec. 1990},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {33},
    number = {12},
    issn = {0001-0782},
    url = {ftp://ftp.cs.wisc.edu/paradyn/technical_papers/fuzz.pdf},
    doi = {10.1145/96267.96279},
    abstract = {The following section describes the tools we built to test the utilities. These tools include the fuzz (random character) generator, ptyjig (to test interactive utilities), and scripts to automate the testing process. Next, we will describe the tests we performed, giving the types of input we presented to the utilities. Results from the tests will follow along with an analysis of the results, including identification and classification of the program bugs that caused the crashes. The final section presents concluding remarks, including suggestions for avoiding the types of problems detected by our study and some commentary on the bugs we found. We include an Appendix with the user manual pages for fuzz and ptyjig.},
    journal = {Commun. ACM},
    month = dec,
    pages = {32–44},
    numpages = {13}
}

@misc{FuzzRevisited,
    author = {Miller, Barton and Koski, David and Lee, Cjin and Maganty, Vivekananda and Murthy, Ravi and Natarajan, Ajitkumar and Steidl, Jeff},
    year = {1998},
    url= {ftp://ftp.cs.wisc.edu/paradyn/technical_papers/fuzz-revisited.pdf},
    title = {Fuzz Revisited: A Re-Examination of the Reliability of UNIX Utilities and Services}
}

@misc{Fuzz2020,
    title={The Relevance of Classic Fuzz Testing: Have We Solved This One?},
    author={Barton P. Miller and Mengxiao Zhang and Elisa R. Heymann},
    url={https://arxiv.org/pdf/2008.06537.pdf},
    year={2020},
    eprint={2008.06537},
    archivePrefix={arXiv},
    primaryClass={cs.SE}
}

@ARTICLE{AFLFast,
    author={M. {Böhme} and V. {Pham} and A. {Roychoudhury}},
    url={https://mboehme.github.io/paper/TSE18.pdf},
    doi={10.1109/TSE.2017.2785841},
    journal={IEEE Transactions on Software Engineering},
    title={Coverage-Based Greybox Fuzzing as Markov Chain},
    year={2019},
    volume={45},
    number={5},
    pages={489-506},
}

@inproceedings{FairFuzz,
    author = {Lemieux, Caroline and Sen, Koushik},
    title = {FairFuzz: A Targeted Mutation Strategy for Increasing Greybox Fuzz Testing Coverage},
    year = {2018},
    isbn = {9781450359375},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://www.carolemieux.com/fairfuzz-ase18.pdf},
    doi = {10.1145/3238147.3238176},
    booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
    pages = {475–485},
    numpages = {11},
    keywords = {rare branches, fuzz testing, coverage-guided greybox fuzzing},
    location = {Montpellier, France},
    series = {ASE 2018}
}
