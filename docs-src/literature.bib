
@article{MacIver2019,
  doi       = {10.21105/joss.01891},
  url       = {https://doi.org/10.21105/joss.01891},
  year      = {2019},
  publisher = {The Open Journal},
  volume    = {4},
  number    = {43},
  pages     = {1891},
  author    = {David MacIver and Zac Hatfield-Dodds and Many Contributors},
  title     = {Hypothesis: A new approach to property-based testing},
  journal   = {Journal of Open Source Software}
}

% TODO: to be replaced by formal citation as soon as one is available
@unpublished{MacIver2020,
  author    = {David MacIver and Alastair Donaldson},
  title     = {Test-Case Reduction via Test-Case Generation: Insights From the Hypothesis Reducer},
  publisher = {ECOOP},
  url       = {https://drmaciver.github.io/papers/reduction-via-generation-preview.pdf},
  note      = {to be published in \url{https://2020.ecoop.org/details/ecoop-2020-papers/13/Test-Case-Reduction-via-Test-Case-Generation-Insights-From-the-Hypothesis-Reducer}}
}

@inproceedings{TargetedPBT,
  author    = {L\"{o}scher, Andreas and Sagonas, Konstantinos},
  title     = {Targeted Property-Based Testing},
  year      = {2017},
  isbn      = {9781450350761},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://proper-testing.github.io/papers/issta2017.pdf},
  doi       = {10.1145/3092703.3092711},
  booktitle = {Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis},
  pages     = {46–56},
  numpages  = {11},
  keywords  = {Search-based testing, PropEr, QuickCheck, Property-based testing},
  location  = {Santa Barbara, CA, USA},
  series    = {ISSTA 2017}
}

@inproceedings{AutomatingTargetedPBT,
  author    = {A. {Löscher} and K. {Sagonas}},
  booktitle = {2018 IEEE 11th International Conference on Software Testing, Verification and Validation (ICST)},
  title     = {Automating Targeted Property-Based Testing},
  url       = {https://proper-testing.github.io/papers/icst2018.pdf},
  doi       = {10.1109/ICST.2018.00017},
  year      = {2018},
  volume    = {},
  number    = {},
  pages     = {70-80}
}

@incollection{fuzzingbook2019,
  author       = {Andreas Zeller and Rahul Gopinath and Marcel B{\"o}hme and Gordon Fraser and Christian Holler},
  booktitle    = {The Fuzzing Book},
  title        = {The Fuzzing Book},
  year         = {2019},
  publisher    = {Saarland University},
  howpublished = {\url{https://www.fuzzingbook.org/}},
  note         = {Retrieved 2019-09-09 16:42:54+02:00},
  url          = {https://www.fuzzingbook.org/},
  urldate      = {2019-09-09 16:42:54+02:00}
}

@article{10.1145/2499370.2462173,
  author     = {Chen, Yang and Groce, Alex and Zhang, Chaoqiang and Wong, Weng-Keen and Fern, Xiaoli and Eide, Eric and Regehr, John},
  title      = {Taming Compiler Fuzzers},
  year       = {2013},
  issue_date = {June 2013},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {48},
  number     = {6},
  issn       = {0362-1340},
  url        = {https://doi.org/10.1145/2499370.2462173},
  doi        = {10.1145/2499370.2462173},
  abstract   = {Aggressive random testing tools ("fuzzers") are impressively effective at finding compiler bugs. For example, a single test-case generator has resulted in more than 1,700 bugs reported for a single JavaScript engine. However, fuzzers can be frustrating to use: they indiscriminately and repeatedly find bugs that may not be severe enough to fix right away. Currently, users filter out undesirable test cases using ad hoc methods such as disallowing problematic features in tests and grepping test results. This paper formulates and addresses the fuzzer taming problem: given a potentially large number of random test cases that trigger failures, order them such that diverse, interesting test cases are highly ranked. Our evaluation shows our ability to solve the fuzzer taming problem for 3,799 test cases triggering 46 bugs in a C compiler and 2,603 test cases triggering 28 bugs in a JavaScript engine.},
  journal    = {SIGPLAN Not.},
  month      = jun,
  pages      = {197–208},
  numpages   = {12},
  keywords   = {fuzz testing, compiler testing, random testing, compiler defect, bug reporting, test-case reduction, automated testing}
}

@inproceedings{TamingCompilerFuzzers,
  author    = {Chen, Yang and Groce, Alex and Zhang, Chaoqiang and Wong, Weng-Keen and Fern, Xiaoli and Eide, Eric and Regehr, John},
  title     = {Taming Compiler Fuzzers},
  year      = {2013},
  isbn      = {9781450320146},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {http://www.cs.utah.edu/~regehr/papers/pldi13.pdf},
  doi       = {10.1145/2491956.2462173},
  abstract  = {Aggressive random testing tools ("fuzzers") are impressively effective at finding compiler bugs. For example, a single test-case generator has resulted in more than 1,700 bugs reported for a single JavaScript engine. However, fuzzers can be frustrating to use: they indiscriminately and repeatedly find bugs that may not be severe enough to fix right away. Currently, users filter out undesirable test cases using ad hoc methods such as disallowing problematic features in tests and grepping test results. This paper formulates and addresses the fuzzer taming problem: given a potentially large number of random test cases that trigger failures, order them such that diverse, interesting test cases are highly ranked. Our evaluation shows our ability to solve the fuzzer taming problem for 3,799 test cases triggering 46 bugs in a C compiler and 2,603 test cases triggering 28 bugs in a JavaScript engine.},
  booktitle = {Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  pages     = {197–208},
  numpages  = {12},
  keywords  = {fuzz testing, bug reporting, compiler defect, test-case reduction, random testing, compiler testing, automated testing},
  location  = {Seattle, Washington, USA},
  series    = {PLDI '13}
}

@article{QuickCheck,
  author    = {Claessen, Koen and Hughes, John},
  title     = {QuickCheck: A Lightweight Tool for Random Testing of Haskell Programs},
  year      = {2000},
  publisher = {Association for Computing Machinery},
  url       = {https://doi.org/10.1145/357766.351266},
  doi       = {10.1145/357766.351266},
  journal   = {Proceedings of the Fifth ACM SIGPLAN International Conference on Functional Programming}
}

@inproceedings{OneTestToRuleThemAll,
  doi       = {10.1145/3092703.3092704},
  url       = {https://agroce.github.io/issta17.pdf},
  year      = {2017},
  publisher = {{ACM} Press},
  author    = {Alex Groce and Josie Holmes and Kevin Kellar},
  title     = {One test to rule them all},
  booktitle = {Proceedings of the 26th {ACM} {SIGSOFT} International Symposium on Software Testing and Analysis - {ISSTA} 2017}
}

@inproceedings{SwarmTesting,
  author    = {Groce, Alex and Zhang, Chaoqiang and Eide, Eric and Chen, Yang and Regehr, John},
  title     = {Swarm Testing},
  year      = {2012},
  isbn      = {9781450314541},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://www.cs.utah.edu/~regehr/papers/swarm12.pdf},
  doi       = {10.1145/2338965.2336763},
  abstract  = { Swarm testing is a novel and inexpensive way to improve the diversity of test cases generated during random testing. Increased diversity leads to improved coverage and fault detection. In swarm testing, the usual practice of potentially including all features in every test case is abandoned. Rather, a large “swarm” of randomly generated configurations, each of which omits some features, is used, with configurations receiving equal resources. We have identified two mechanisms by which feature omission leads to better exploration of a system’s state space. First, some features actively prevent the system from executing interesting behaviors; e.g., “pop” calls may prevent a stack data structure from executing a bug in its overflow detection logic. Second, even when there is no active suppression of behaviors, test features compete for space in each test, limiting the depth to which logic driven by features can be explored. Experimental results show that swarm testing increases coverage and can improve fault detection dramatically; for example, in a week of testing it found 42% more distinct ways to crash a collection of C compilers than did the heavily hand-tuned default configuration of a random tester. },
  booktitle = {Proceedings of the 2012 International Symposium on Software Testing and Analysis},
  pages     = {78–88},
  numpages  = {11},
  location  = {Minneapolis, MN, USA},
  series    = {ISSTA 2012}
}

@article{Fuzz1990,
  author     = {Miller, Barton P. and Fredriksen, Louis and So, Bryan},
  title      = {An Empirical Study of the Reliability of UNIX Utilities},
  year       = {1990},
  issue_date = {Dec. 1990},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {33},
  number     = {12},
  issn       = {0001-0782},
  url        = {ftp://ftp.cs.wisc.edu/paradyn/technical_papers/fuzz.pdf},
  doi        = {10.1145/96267.96279},
  abstract   = {The following section describes the tools we built to test the utilities. These tools include the fuzz (random character) generator, ptyjig (to test interactive utilities), and scripts to automate the testing process. Next, we will describe the tests we performed, giving the types of input we presented to the utilities. Results from the tests will follow along with an analysis of the results, including identification and classification of the program bugs that caused the crashes. The final section presents concluding remarks, including suggestions for avoiding the types of problems detected by our study and some commentary on the bugs we found. We include an Appendix with the user manual pages for fuzz and ptyjig.},
  journal    = {Commun. ACM},
  month      = dec,
  pages      = {32–44},
  numpages   = {13}
}

@misc{FuzzRevisited,
  author = {Miller, Barton and Koski, David and Lee, Cjin and Maganty, Vivekananda and Murthy, Ravi and Natarajan, Ajitkumar and Steidl, Jeff},
  year   = {1998},
  url    = {ftp://ftp.cs.wisc.edu/paradyn/technical_papers/fuzz-revisited.pdf},
  title  = {Fuzz Revisited: A Re-Examination of the Reliability of UNIX Utilities and Services}
}

@misc{Fuzz2020,
  title         = {The Relevance of Classic Fuzz Testing: Have We Solved This One?},
  author        = {Barton P. Miller and Mengxiao Zhang and Elisa R. Heymann},
  url           = {https://arxiv.org/pdf/2008.06537.pdf},
  year          = {2020},
  eprint        = {2008.06537},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@article{AFLFast,
  author  = {M. {Böhme} and V. {Pham} and A. {Roychoudhury}},
  url     = {https://mboehme.github.io/paper/TSE18.pdf},
  doi     = {10.1109/TSE.2017.2785841},
  journal = {IEEE Transactions on Software Engineering},
  title   = {Coverage-Based Greybox Fuzzing as Markov Chain},
  year    = {2019},
  volume  = {45},
  number  = {5},
  pages   = {489-506}
}

@inproceedings{FairFuzz,
  author    = {Lemieux, Caroline and Sen, Koushik},
  title     = {FairFuzz: A Targeted Mutation Strategy for Increasing Greybox Fuzz Testing Coverage},
  year      = {2018},
  isbn      = {9781450359375},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://www.carolemieux.com/fairfuzz-ase18.pdf},
  doi       = {10.1145/3238147.3238176},
  booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
  pages     = {475–485},
  numpages  = {11},
  keywords  = {rare branches, fuzz testing, coverage-guided greybox fuzzing},
  location  = {Montpellier, France},
  series    = {ASE 2018}
}

@article{AFLSmart,
  author  = {V. {Pham} and M. {B{\"o}hme} and A. E. {Santosa} and A. R. {Caciulescu} and A. {Roychoudhury}},
  journal = {IEEE Transactions on Software Engineering},
  title   = {Smart Greybox Fuzzing},
  year    = {2019},
  doi     = {10.1109/TSE.2019.2941681},
  url     = {https://thuanpv.github.io/publications/TSE19_aflsmart.pdf}
}

@inproceedings{EnFuzz,
  title     = {EnFuzz: Ensemble Fuzzing with Seed Synchronization among Diverse Fuzzers},
  author    = {Yuanliang Chen and Yu Jiang and Fuchen Ma and Jie Liang and Mingzhe Wang and Chijin Zhou and Xun Jiao and Zhuo Su},
  booktitle = {USENIX Security Symposium},
  year      = {2019},
  url       = {https://www.usenix.org/system/files/sec19-chen-yuanliang.pdf}
}

@misc{FullSpeedFuzzing,
  title         = {Full-speed Fuzzing: Reducing Fuzzing Overhead through Coverage-guided Tracing},
  author        = {Stefan Nagy and Matthew Hicks},
  year          = {2018},
  eprint        = {1812.11875},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR},
  url           = {https://arxiv.org/pdf/1812.11875.pdf}
}

@inproceedings{AFLgo,
  author    = {B\"{o}hme, Marcel and Pham, Van-Thuan and Nguyen, Manh-Dung and Roychoudhury, Abhik},
  title     = {Directed Greybox Fuzzing},
  year      = {2017},
  isbn      = {9781450349468},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://mboehme.github.io/paper/CCS17.pdf},
  doi       = {10.1145/3133956.3134020},
  abstract  = {Existing Greybox Fuzzers (GF) cannot be effectively directed, for instance, towards problematic changes or patches, towards critical system calls or dangerous locations, or towards functions in the stack-trace of a reported vulnerability that we wish to reproduce. In this paper, we introduce Directed Greybox Fuzzing (DGF) which generates inputs with the objective of reaching a given set of target program locations efficiently. We develop and evaluate a simulated annealing-based power schedule that gradually assigns more energy to seeds that are closer to the target locations while reducing energy for seeds that are further away. Experiments with our implementation AFLGo demonstrate that DGF outperforms both directed symbolic-execution-based whitebox fuzzing and undirected greybox fuzzing. We show applications of DGF to patch testing and crash reproduction, and discuss the integration of AFLGo into Google's continuous fuzzing platform OSS-Fuzz. Due to its directedness, AFLGo could find 39 bugs in several well-fuzzed, security-critical projects like LibXML2. 17 CVEs were assigned.},
  booktitle = {Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
  pages     = {2329–2344},
  numpages  = {16},
  keywords  = {directed testing, verifying true positives, coverage-based greybox fuzzing, crash reproduction, reachability, patch testing},
  location  = {Dallas, Texas, USA},
  series    = {CCS '17}
}

@misc{TOFU,
  title         = {TOFU: Target-Oriented FUzzer},
  author        = {Zi Wang and Ben Liblit and Thomas Reps},
  year          = {2020},
  eprint        = {2004.14375},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE},
  url           = {https://arxiv.org/pdf/2004.14375.pdf}
}

@inproceedings{MOpt-AFL,
  author    = {Chenyang Lyu and Shouling Ji and Chao Zhang and Yuwei Li and Wei-Han Lee and Yu Song and Raheem Beyah},
  title     = {{MOPT}: Optimized Mutation Scheduling for Fuzzers},
  booktitle = {28th {USENIX} Security Symposium ({USENIX} Security 19)},
  year      = {2019},
  isbn      = {978-1-939133-06-9},
  address   = {Santa Clara, CA},
  pages     = {1949--1966},
  url       = {https://www.usenix.org/conference/usenixsecurity19/presentation/lyu},
  publisher = {{USENIX} Association},
  month     = aug
}

@inproceedings{AssuranceInTestingRoadmap,
  author    = {B\"{o}hme, Marcel},
  title     = {Assurance in Software Testing: A Roadmap},
  year      = {2019},
  publisher = {IEEE Press},
  url       = {https://arxiv.org/pdf/1807.10255.pdf},
  doi       = {10.1109/ICSE-NIER.2019.00010},
  booktitle = {Proceedings of the 41st International Conference on Software Engineering: New Ideas and Emerging Results},
  pages     = {5–8},
  numpages  = {4},
  location  = {Montreal, Quebec, Canada},
  series    = {ICSE-NIER '19}
}

@article{STADS,
  author     = {B\"{o}hme, Marcel},
  title      = {STADS: Software Testing as Species Discovery},
  year       = {2018},
  issue_date = {July 2018},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {27},
  number     = {2},
  issn       = {1049-331X},
  url        = {https://mboehme.github.io/paper/TOSEM18.pdf},
  doi        = {10.1145/3210309},
  journal    = {ACM Trans. Softw. Eng. Methodol.},
  month      = jun,
  articleno  = {7},
  numpages   = {52}
}

@inproceedings{ExponentialCost,
  author    = {B\"{o}hme, Marcel and Falk, Brandon},
  title     = {Fuzzing: On the Exponential Cost of Vulnerability Discovery},
  year      = {2020},
  publisher = {Association for Computing Machinery},
  url       = {https://mboehme.github.io/paper/FSE20.EmpiricalLaw.pdf},
  booktitle = {Proceedings of the ACM European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE) 2020}
}

@article{FuzzFactory,
  doi       = {10.1145/3360600},
  url       = {https://dl.acm.org/doi/pdf/10.1145/3360600},
  year      = {2019},
  month     = oct,
  publisher = {Association for Computing Machinery ({ACM})},
  volume    = {3},
  number    = {{OOPSLA}},
  pages     = {1--29},
  author    = {Rohan Padhye and Caroline Lemieux and Koushik Sen and Laurent Simon and Hayawardh Vijayakumar},
  title     = {{FuzzFactory}: domain-specific fuzzing with waypoints},
  journal   = {Proceedings of the {ACM} on Programming Languages}
}

@inproceedings{Nezha,
  author    = {T. {Petsios} and A. {Tang} and S. {Stolfo} and A. D. {Keromytis} and S. {Jana}},
  booktitle = {2017 IEEE Symposium on Security and Privacy (SP)},
  title     = {NEZHA: Efficient Domain-Independent Differential Testing},
  year      = {2017},
  url       = {https://www.ieee-security.org/TC/SP2017/papers/390.pdf},
  pages     = {615-632}
}

@inproceedings{JQF,
  doi       = {10.1145/3293882.3339002},
  url       = {https://cs.berkeley.edu/~rohanpadhye/files/zest-issta19.pdf},
  year      = {2019},
  publisher = {{ACM} Press},
  author    = {Rohan Padhye and Caroline Lemieux and Koushik Sen},
  title     = {{JQF}: coverage-guided property-based testing in Java},
  booktitle = {Proceedings of the 28th {ACM} {SIGSOFT} International Symposium on Software Testing and Analysis - {ISSTA} 2019}
}

@inproceedings{Zest,
  doi       = {10.1145/3293882.3330576},
  url       = {https://people.eecs.berkeley.edu/~rohanpadhye/files/zest-issta19.pdf},
  year      = {2019},
  publisher = {{ACM} Press},
  author    = {Rohan Padhye and Caroline Lemieux and Koushik Sen and Mike Papadakis and Yves Le Traon},
  title     = {Semantic fuzzing with zest},
  booktitle = {Proceedings of the 28th {ACM} {SIGSOFT} International Symposium on Software Testing and Analysis - {ISSTA} 2019}
}

@inproceedings{RLCheck,
  author    = {Sameer Reddy and Caroline Lemieux and Rohan Padhye and Koushik Sen},
  title     = {Quickly Generating Diverse Valid Test Inputs with Reinforcement Learning},
  year      = {2020},
  publisher = {IEEE Press},
  url       = {https://www.carolemieux.com/rlcheck_preprint.pdf},
  booktitle = {Proceedings of the 42st International Conference on Software Engineering}
}
